{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lorentzian vs. Gaussian\n",
    "Use tensorflow.keras to build a simple binary\n",
    "classifier that can distinguish between\n",
    "one-dimensional Lorentzians $L(x)$ and Gaussians\n",
    "$N(x)$ where:\n",
    "\\begin{equation}\n",
    "    L(x)=\\frac{A}{(x-\\mu)^2\\sigma^2+1}\\\\\n",
    "    N(x)=Ae^{(x-\\mu)^2/(2\\sigma^2)}\n",
    "\\end{equation}\n",
    "Here A is the amplitude, $\\mu$ the location of the peaks, and $\\sigma$ the width. You are free to choose any\n",
    "values for these you like, but I suggest you start simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('./include/notebook.mplstyle')\n",
    "np.set_printoptions(linewidth=120)\n",
    "ml4s._set_css_style('./include/bootstrap.css')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from tqdm import trange,tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a\n",
    "Write a function that can generate your dataset. This should include a large number of random\n",
    "functions $L$ and $N$ on the line -5$\\leq x \\leq$ 5 where A, $\\sigma$, $\\mu$ are uniformly distributed random\n",
    "numbers as seen in the figure. The input values will be either $N(x)$ or $L(x)$ while the targets\n",
    "are 1 for Gaussian and 0 for Lorentzian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(size):\n",
    "    A=tf.keras.initializers.RandomUniform(minval=-5.0, maxval=5.0, seed=None)\n",
    "    σ=tf.keras.initializers.RandomUniform(minval=-5.0, maxval=5.0, seed=None)\n",
    "    μ=tf.keras.initializers.RandomUniform(minval=-5.0, maxval=5.0, seed=None)\n",
    "    x=np.linspace(-5,-5, 1000)\n",
    "    choice=tf.keras.initializers.RandomUniform(minval=-1, maxval=1, seed=None)\n",
    "    spot=0\n",
    "    y=np.zeros(len(x))\n",
    "    if choice>=0:\n",
    "        target[spot]=1\n",
    "        spot+=1\n",
    "        for i in len(x):\n",
    "            y[i]=A/(((x[i]-μ)**2)*(σ**2)+1)\n",
    "    else:\n",
    "        target[spot]=0\n",
    "        spot+=1\n",
    "        for i in len(x):\n",
    "            holder=(x[i]-μ)**2/(2*σ**2)\n",
    "            y[i]=A*np.exp(holder)\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b\n",
    "Using the binary cross entropy as your cost function, train your network to distinguish between\n",
    "them. What level of accuracy can you achieve with 10 functions? 100? 1000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(rectangles, labels, test_size=0.1)\n",
    "\n",
    "model = keras.Sequential(\n",
    "[\n",
    "    layers.Dense(256,input_shape=(L*L,),activation='relu'),\n",
    "    layers.Dense(128,input_shape=(L*L,),activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256,input_shape=(L*L,),activation='relu'),\n",
    "    layers.Dense(4,input_shape=(L*L,),activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid', bias_initializer='zeros')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy']) \n",
    "batch_size = 100\n",
    "epochs = 30\n",
    "training_history = {}\n",
    "training_history['test'] = model.fit(x_train,y_train, epochs=epochs,validation_data=(x_test,y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "predictions = np.zeros(rectangles.shape[0],dtype=int)\n",
    "predictions[np.where(model(rectangles)>=0.5)[0]] = 1\n",
    "\n",
    "mistakes = np.where(labels != predictions)[0]\n",
    "num_mistakes = len(mistakes)\n",
    "\n",
    "print(f'Num. Mistakes  = {num_mistakes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c\n",
    "How does the performance of your deep neural network compare to logistic\n",
    "regression? You can either write your own code to do this, or use some libraries (like\n",
    "scikit.learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ml4s)",
   "language": "python",
   "name": "ml4s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
