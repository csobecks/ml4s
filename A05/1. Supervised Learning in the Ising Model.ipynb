{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Supervised Learning in the Ising Model\n",
    "This question is based on our in-class tutorial which focused on generating the first figure in J.\n",
    "Carrasquilla and R. G. Melko, Nat. Phys. 13, 431 (2017). https://arxiv.org/abs/1605.01735\n",
    "\n",
    "Using the Monte Carlo code we wrote in class, I generated 16000 2D Ising spin configurations with\n",
    "L = 30 (Ising2D_config_L30.dat.gz), labelled them with 1 = T > Tc, 0 = T < Tc,\n",
    "(Ising2D\\_labels\\_L30.dat) and stored the temperatures at which the configurations were generated\n",
    "(Ising2D\\_temps\\_L30.dat). These are available in the course repository in the data\n",
    "folder.\n",
    "\n",
    "(a) Create a randomized train/validate/test split from the data and encode the labels as 1-hot\n",
    "vectors. Until now we have only used a single split for training and testing. When we want\n",
    "to evaluate a network after tuning hyperparamters it is considered best-practice to keep a\n",
    "subset of data that the network never sees until final testing. This provides a fully unbiased\n",
    "estimate of generalization and accuracy. While there are no absolute rules, 80/10/10 is\n",
    "common.\n",
    "\n",
    "(b) Train a neural network (architecture of your choice) until the accuracy converges. Plot both\n",
    "the accuracy and cost as function of training epoch. Make sure to discuss any possible evidence\n",
    "of overfitting.\n",
    "\n",
    "(c) Study the effects of adjusting hyperparamters. You can consider: Training algorithm (stochastic\n",
    "gradient descent, adam, . . . ), number of layers, number of neurons, DNN, CNN, etc. Make\n",
    "sure to record the training log for each of these changes.\n",
    "\n",
    "(d) Check your final accuracy using the test data set. Make sure to clearly display your final\n",
    "accuracy.\n",
    "\n",
    "(e) Study your networkâ€™s performance as a function of temperature. Make a plot of the:\n",
    "\n",
    "i. average accuracy as a function of temperature,\n",
    "\n",
    "ii. average output from each of the two output neurons (soft-max) as a function of temperature.\n",
    "    \n",
    "Compare your results with Figure 1 of the Carrasquilla and Melko reference. Hint: look into np.unique() to simplify your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ml4s)",
   "language": "python",
   "name": "ml4s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
